# Image Classification with Python APIs

## Introduction
This tutorial shows three examples of how to deploy Deep CNNs on FPGAs using our Python APIs.

Once a network has been compiled and quantized, you will walk through deploying in different modes.

The (Compiler, Quantizer) outputs for both GoogLeNet-v1 and Resnet-50 are included in the "data" directory.

**Compiler Outputs**: Commands File (HW Instructions "cmds"), model_data directory with preprocessed floating point weights.
**Quantizer Outputs**: JSON FILE containing scaling factors for each layer in the corresponding network.  

Notes:
 - The final layers of the network (Fully connected, Softmax) are run on the CPU, as those layers are not supported by the FPGA
 - The batch_classify example will require you to download the imagnet validation set, and place the images [here](../../models/data/ilsvrc12/ilsvrc12_img_val/replace_this_file_with_dataset.md)  
 - Amazon AWS EC2 F1 requires root privileges to load the FPGA, so use `sudo` to invoke run.sh

The following three examples of applications using the Python xfDNN API are provided:

1. A **Test Classification** example that demonstrates how to run inference using GoogLeNet-v1 on a single image "dog.jpg"
2. A **Batch Classifcation** example that streams images from disk through the FPGA for classification.
3. A **Multi-Process** example that shows different DNNs running on different kernels on the FPGA.

## Directory overview

```
ml-suite/
└── examples
    └── classification
        ├── README.md
        ├── run.sh ## IMPORTANT
        ├── test_classify.py
        ├── batch_classify.py
        ├── test_classify_async_multinet.py
        ├── imagenet_val
        ├── dog.jpg
        ├── gold.txt
        ├── synset_words.txt
        └── data                                                                                           
            ├── googlenet_v1_16b.json                                                                      
            ├── googlenet_v1_28.cmd                                                                        
            ├── googlenet_v1_56.cmd                                                                        
            ├── googlenet_v1_8b.json                                                                       
            ├── googlenet_v1_data                                                                          
            ├── multinet.json                                                                              
            ├── resnet50_16b.json                                                                          
            ├── resnet50_28.cmd                                                                            
            └── resnet50_data                                                                              

```

## Running the Examples  

To run any of the three examples, use the provided bash run.sh script. 

1. Start Anaconda.
    ```sh
    $ conda activate ml-suite
    ```

2. Navigate to the `ml-suite/examples/classification` dir.
    ```sh
    $ cd ml-suite/examples/classification
    ```

3. Run the example by executing ` run.sh` followed by the following parameters:
    - `hardware` Valid values are `aws`, `nimbix` or `1525`
    - `example` - Valid values are `test_classify` or `batch_classify` or `multinet`
    - `kernel size` - Valid values are `med` or `large` - Used to select overlaybins
    - `quantization precision` - Valid values are `16` or `8` - corresponding to INT16 or INT8

    Usage: `./run.sh` `hardware` `example` `kernel size` `quantization precision`

    Note: `Sudo` is required to run any of the scripts in AWS.

4. Single Image Classification on AWS, with medium kernels:
    ```sh
    $ sudo ./run.sh aws test_classify med 16
    ```

5. Streaming Image Classification on VCU1525 with large kernels:
    ```sh
    $ ./run.sh 1525 batch_classify large 8
    ```
6. Multinet Image Classification on Nimbix (Currently, for Multinet only the med size kernel and 16b precision are supported)
    ```sh
    sudo ./run.sh nimbix multinet
    ```


## Example Script Switches
Take a look at the following scripts to understand the examples:
* run.sh
* test_classify.py
* batch_classify.py
* test_classify_async_multinet.py  

The scripts use the arg parser defined in [xdnn_io.py](../../xfdnn/rt/xdnn_io.py)

- `--xclbin` 		- Defines which FPGA binary overlay to use. The available binaries are stored in [overlaybins](../../overlaybins)
- `--netcfg` 	    - FPGA instructions generated by the Compiler for the network being ran
- `--quantcfg`      - Path to json file to use for quantization (The json file contains scaling params)
- `--fpgaoutsz`	    - Flattened size of the final activation computed by FPGA (The FPGA will not do FC layers or Softmax)
- `--firstfpgalayer` - Name of first FPGA layer i.e. conv0 (required by quantization code)
- `--datadir`		- Path to data files to run for the network (weights)
- `--labels`		- Path to text file containing line seperated labels
- `--xlnxlib`		- Path to xfDNN library file (Middleware)
- `--useblas`		- Use BLAS-optimized functions
- `--golden`		- Path to text file containing line seperated correct labels
- `--imagedir`	    - Directory with image files to classify (Only applicable to batch_classify)
- `--jsoncfg`       - Path to json file used to define seperate networks (Only applicable to multinet)

For Multinet deployments, the different models/networks are set in the `--jsoncfg` file. For the Multinet example given above, see how to set the arguments here [multinet.json][]

## Example Output From Single Image Classification


  ```sh
  $ ./run.sh 1525 test_classify med 16
  =============== pyXDNN =============================
  [XBLAS] # kernels: 1
  Linux:4.4.0-121-generic:#145-Ubuntu SMP Fri Apr 13 13:47:23 UTC 2018:x86_64
  Distribution: Ubuntu 16.04.2 LTS
  GLIBC: 2.23
  ---

  ---
  CL_PLATFORM_VENDOR Xilinx
  CL_PLATFORM_NAME Xilinx
  CL_DEVICE_0: 0x175a1d0
  CL_DEVICES_FOUND 1, using 0
  loading /home/bryanloz/DEEPXILINX/MLsuite/overlaybins/1525/xdnn_28_16b.xclbin
  [XBLAS] kernel0: kernelSxdnn_0
  [XDNN] loading xclbin settings from /home/bryanloz/DEEPXILINX/MLsuite/overlaybins/1525/xdnn_28_16b.xclbin.json
  [XDNN] using custom DDR banks 2,2,1,1

  [XDNN] kernel configuration
  [XDNN]   num cores       : 2
  [XDNN]   dsp array width : 28
  [XDNN]   img mem size    : 4 MB
  [XDNN]   version         : 2.1
  [XDNN]   8-bit mode      : 0
  [XDNN]   Max Image W/H   : 0
  [XDNN]   Max Image Depth : 0

  Loading weights/bias/quant_params to FPGA...

  After FPGA (1915.318012 ms)

  After FC (7.054090 ms)

  After Softmax (6.752014 ms)


  ---------- Prediction 0 for dog.jpg ----------
  0.7376 - "n02112018 Pomeranian"
  0.0785 - "n02123394 Persian cat"
  0.0365 - "n02085620 Chihuahua"
  0.0183 - "n02492035 capuchin, ringtail, Cebus capucinus"
  0.0150 - "n02094433 Yorkshire terrier"


  Success!
  ```

  [multinet.json]: data/multinet.json
