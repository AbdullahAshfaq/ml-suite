# ML-Suite Python APIs to run inference on a single image

The python APIs provide users an easy way to deploy Deep CNNs on FPGA. 

## 1. Prerequisites

**A. XFDNN compiler outputs**
  - `compiler JSON` : File containing low level hardware instructions.
  - `model_data.h5` : File containing preprocessed floating point data (weights/biases).
  - `quantizer JSON` : File containing scaling factors for each layer in the corresponding network.

**B. <a name="argslist"></a>List of arguments needed by python API**
  - `xclbin` : (String) Path to the binary image to be loaded.
  - `netcfg` : (String) Path to compiler JSON.
  - `weights` : (String) Path to `model_data.h5` file generated by compiler.
  - `labels` : (String) Path to text file containing line separated labels for prediction.
  - `quantizecfg` : (String) Path to quantizer JSON file.
  - `img_input_scale` : (Float) Input image scaling factor. Default value is `1.0`.
  - `images` : (String) Image Directory or raw image file to use as input.
  - `golden` : (String) Path to text file containing line separated correct labels.
  - `jsoncfg` - (String) Path to JSON file used to define separate networks (Only applicable to multi-net).

>**:pushpin: NOTE:** These are the minimum set of arguments required. Some of python API calls don't need all arguments.

Below are the list of API.

## 2. Import Python API

All XFDNN python API modules can be imported from `<MLSuite>/xfdnn/rt/xdnn_io.py` and `<MLSuite>/xfdnn/rt/xdnn.py`. Make sure to import these modules before invoking python API.

```Python
from xfdnn.rt import xdnn, xdnn_io
```

## 3. Create Argument Dictionary

Parses the list of input arguments and creates argument dictionary. Sets XFDNN library environment.

```Python
args = processCommandLine(
                         argv = None
                         )
```
**Parameters**

***Inputs***
  - `argv` : (List) List of input arguments. Refer to [List of arguments needed by python API](#argslist) section for more details.

***Outputs***
 - `args` : (Dictionary) Returns dictionary of arguments which are needed by python API.

## 4. Create Handle

Programs a hardware acceleration engine to the FPGA and initializes communication. Loads the kernel from xclbin and creates kernel object.

**Syntax**
```python
Ret, handles = xdnn.createHandle(
                                xclbin,
                                kernel="kernelSxdnn_0",
                                deviceIdx = [0]
                                )
```
**Parameters**

***Inputs***
 - `xclbin`		: (String) Path to the design bit-stream to be loaded.
 - `kernel`   : (String) Name of the kernel in xclbin. Always use `kernelSxdnn_0` .
 - `deviceIdx` : (List) List of device ids to create handles for.

***Outputs***
 - `Ret` : (Integer) Returns zero upon successful execution otherwise `-1` value.
 - `handles` : (List) Returns list of handles, one handle per device.


## 5. Create Instance of XDNNFPGAOp

Create instance of the class `XDNNFPGAOp`. This will load weights, biases and quantization parameters to FPGA using `model_data.h5` file generated by compiler.

**Syntax**
```python
fpgaRT = xdnn.XDNNFPGAOp(
                        handles,
                        args
                        )
```
**Parameters**

***Inputs***
 - `handles` : (List) List of handles which are created by `createHandle()` API.
 - `args` : (Dictionary) Dictionary of arguments. Refer to [List of arguments needed by python API](#argslist) section for more details.

 ***Outputs***
 - `fpgaRT` : (Instance) Instance of the class `XDNNFPGAOp`.

## 6. Load I/O Nodes

Generates input and output nodes. `XDNNFPGAOp` provides `getOutputs()` and `getInputs()` methods which are used to load I/O nodes.

 **Syntax**
 ```python
 fpgaOutput =  fpgaRT.getOutputs()
 fpgaInput = fpgaRT.getInputs()
 ```
 **Parameters**

  ***Outputs***
  - `fpgaOutput` : (Dictionary) Dictionary of output nodes. Output data of inference is stored here.
  - `fpgaInput` : (Dictionary) Dictionary of input nodes. Input data of inference to be filled here.

## 7. Prepare Input

Below are the sequence of APIs needed for loading of input data from image.

#### A. Get Input Handle

Get the handle from input node loaded by `getInputs()` API.

```python
firstInput = list(fpgaInput.values())[0]
```

**Parameters**
 - `firstInput` : (Numpy Array) A numpy array where input to the inference to be filled with.


#### B. Get Image Paths

Defined in `<MLSuite>/rt/xdnn_io.py`. Generates list of image paths for the given image directory or image file.

**Syntax**
```python
img_path_list = xdnn_io.getFilePaths(
                                    image_path
                                    )
```
**Parameters**

***Inputs***
 - `image_path` : (String) Path to image file or directory.

 ***Outputs***
 - `img_path_list` : (List) Returns list of image paths.


#### C. Load Image Data

Loads image and performs resize and mean subtraction.

**Syntax**
```python
firstInput = xdnn_io.loadImageBlobFromFile(
                                          img_path,
                                          raw_scale,
                                          mean,
                                          input_scale,
                                          img_h,
                                          img_w
                                          )
```
**Parameters**

***Inputs***
 - `img_path` : (String) Path to the input image.
 - `raw_scale` : (Float) Raw-scale is a scale of input data. The model expects pixels to be normalized, so if the input data has values between 0 and 255, then raw_scale should be set to 255. If the data has values between 0 and 1, then raw_scale should be set to 1.
 - `mean` : (List) Image mean values.
 - `input_scale` : (Float) Input scale is a scaling factor. It should be as same the value used in training.
 - `img_h` : (Integer) Image height.
 - `img_w` : (Integer) Image width.

***Outputs***
 - `firstInput` : (Numpy Array) Returns mean subtracted array.

## 8. Execute Inference

`XDNNFPGAOp` provides `execute()` and `exec_async()` methods which supports synchronous and asynchronous modes of execution on FPGA.

#### A. Synchronous Mode

For running single network XFDNN uses synchronous mode of execution. Refer to example  <a href="../examples/deployment_modes/test_classify.py">test_classify.py</a> for more details.

**Syntax**
```python
fpgaRT.execute(
              fpgaInput,
              fpgaOutput,
              streamId = 0,
              blocking = True
              )
```
**Parameters**

***Inputs***
 - `fpgaInput` : (Dictionary) Dictionary of input nodes. This is loaded using `getInputs()` API. Array holding the input data for which to run inference.
 - `streamId` :  (Integer) Optional. Index of the network in case of multiple networks. Set to zero in synchronous mode.
 - `blocking` : (Boolean) Optional. Set to True for synchronous mode otherwise False.

***Outputs***
 - `fpgaOutput` :  (Dictionary) Array holding the result of inference ran on the hardware accelerator.  

#### B. Asynchronous Mode

For running multiple networks XFDNN uses asynchronous mode of execution. Refer to example <a href="../examples/deployment_modes/test_classify_async_multinet.py">test_classify_async_multinet.py</a> for more details.

**Syntax**
```python
fpgaRT.exec_async(
                 fpgaInput,
                 fpgaOutput,
                 streamId = 0
                 )
```

**Parameters**

***Inputs***
 - `fpgaInput` : (Dictionary) Dictionary of input nodes which is loaded by `getInputs()` API. Array holding the input data for which to run inference.
 - `streamId` :  (Integer) Index of the network in case of multiple networks.

***Outputs***
 - `fpgaOutput` :  (Dictionary) Array holding the result of inference ran on the hardware accelerator.

#### C. Get Results in Asynchronous Execution Mode

Get result of execution for a given PE, and a given stream.

**Syntax**
```python
fpgaRT.get_result(
                 streamId=0
                 )
```
**Parameters**

***Inputs***
 - `streamId` :  (Integer) Optional. Index of the network in case of multiple networks.

## 9. Execute Fully connected Layers

Below are the sequence of APIs needed for executing the Fully connected layers.

#### A. Load FC Layer Data

Defined in `<MLSuite>/rt/xdnn_io.py`. This API loads Fully connected layers data (weights/biases). This makes use of `model_data.h5` file generated by compiler.

**syntax**
```python
fcWeight, fcBias = xdnn_io.loadFCWeightsBias(
                                            args
                                            )
```
**Parameters**

***Inputs***
- `args` : (Dictionary) Dictionary of arguments. Refer to [List of arguments needed by python API](#argslist) section for more details.

***Outputs***
 - `fcWeight` : (Numpy Array) Returns weights corresponding to FC layer.
 - `fcBias` : (Numpy Array) Returns biases corresponding to FC layer.

#### B. Get Output Handle

Get the handle from ouput node loaded by `getOutputs()` API.

```python
fcInput = list(fpgaOutput.values())[0]
```

**Parameters**
 - `fcInput` : (Numpy Array) A numpy array holding the output of the inference.


#### C. Execute

Defined in `<MLSuite>/rt/xdnn.py`. Executes the fully connected layer for given single activation or set of activations.

**syntax**
```Python
xdnn.computeFC(
              fcWeight,
              fcBias,
              fcInput,
              fcOutput
              )
```
**Parameters**

***Inputs***
 - `fcWeight` : (Numpy Array) Weights corresponding to the inner product layer.
 - `fcBias` : (Numpy Array) Biases corresponding to the inner product layer.
 - `fcInput` : (Numpy Array) Activation or set of activations corresponding to multiple images stored as a 1D array.

***Outputs***
 - `fcOutput` : (Numpy Array) Inner product result.


## 10. Execute Softmax

Defined in `<MLSuite>/rt/xdnn.py`. Compute the softmax of a given activation or set of activations.

**syntax**
```python
Softmaxout = xdnn.computeSoftmax(
                                data
                                )
```
**Parameters**

***Inputs***
 - `data` : (Numpy Array) Activation or a set of activations corresponding to multiple images stored as a 1D Array.

***Outputs***
 - `softmaxout` : (Numpy Array) Returns softmax activation.

## 11. Classification Results

Below are the sequence of API needed for getting classification results.

#### A. Generate Label List

Reads the given label file and generates a list.

Label file contains the class names which are labeled from 0 to n-1 order where n is number of classes. Refer to  <a href="../examples/deployment_modes/synset_words.txt">sysnet_words.txt</a> file for example ImageNet dataset.

**syntax**
```python
labels_list = xdnn_io.get_labels(
                                label_file
                                )
```

**Parameters**

***Inputs***
 - `label_file` : (String) Path to label file.

***Outputs***
 - `labels_list` : (List) Returns list of sysnet-name pairs.

#### B. Generate Classification Results

Defined in `<MLSuite>/rt/xdnn_io.py`. Prints the result of classification(topK predictions) for given class scores, and a synset labels file.

**syntax**
```python
xdnn_io.printClassification(
                            softmaxOut,
                            img_path_list,
                            labels,
                            topK = 5
                            )
```
**Parameters**

***Inputs***
 - `softmaxOut` : (Integer) Output of softmax layer.
 - `img_path_list` : (List) List of image paths generated by `getFilePaths()` API.
 - `labels` : (List) List of image paths generated by `get_labels()` API.
 - `topK` : (Integer) Number of top predictions to print. Default value is 5.

Below is the example output from single image classification.

```c++
---------- Prediction 1/4 for /opt/ml-suite/examples/deployment_modes/dog.jpg ----------
0.5986 "n02112018 Pomeranian"
0.2033 "n02123394 Persian cat"
0.0319 "n02492035 capuchin, ringtail, Cebus capucinus"
0.0271 "n02085620 Chihuahua"
0.0198 "n02123597 Siamese cat, Siamese"
```

## 12. Release Handle

Defined in `<MLSuite>/rt/xdnn.py`. Terminates the communication by destroying handle. No return value.

**syntax**
```python
xdnn.closeHandle()
```

## References

 - Refer to example <a href="../examples/deployment_modes/test_classify.py">test_classify.py</a> for use case the python API.
 - Refer to example <a href="../examples/deployment_modes/test_classify_async_multinet.py">test_classify_async_multinet.py</a> for multi-net deployments.
